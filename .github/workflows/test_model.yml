name: Model tests

on:
  workflow_call:
    inputs:
      region:
        description: 'Region where the Artifact Registry is located'
        type: string
        required: true
      docker_image_tag: # It should be in the form as mentioned in our internal docs. Just pass insensitive data here like huggingface-text-generation-inference-${accelerator}.${version}:latest
        description: 'Docker Image Tag'
        type: string
        required: true
      gcp_artifact_registry_repository:
        description: 'GCP Artifact Registry Repository'
        type: string
        required: true
      GCP_PROJECT_ID:
        description: 'GCP Project ID'
        required: true
    secrets:
      GCP_SERVICE_ACCOUNT_JSON_KEY:
        description: 'Service Account'
        required: true

env:
  HF_HOME: /mnt/cache
  # For gated repositories, we still need to agree to share information on the Hub repo. page in order to get access.
  # This token is created under the bot `hf-transformers-bot`.
  HF_HUB_READ_TOKEN: ${{ secrets.HF_HUB_READ_TOKEN }}

jobs:
  run_test:
    name: github repo
    runs-on: [single-gpu, nvidia-gpu, a10, ci]
    container:
      image: ${{ inputs.region }}-docker.pkg.dev/${{ inputs.GCP_PROJECT_ID }}/${{ inputs.gcp_artifact_registry_repository }}/${{ inputs.docker_image_tag }}
      options: --gpus all --shm-size "16gb" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/
      credentials:
        username: _json_key
        password: ${{ secrets.GCP_SERVICE_ACCOUNT_JSON_KEY }}
    steps:
      - name: Echo
        shell: bash
        run: |
          ls -l
          ls -la
#
#      - name: run tests
#        run: |
#          python3 -m pytest -v tests/models
