{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Golden Gate 7B on Vertex AI \n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/prediction/llm_streaming_prediction.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "        <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official//prediction/llm_streaming_prediction.ipynb\">\n",
    "        <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "        </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official//prediction/llm_streaming_prediction.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial demonstrates how to deploy Llama to Vertex AI using Hugging Face Text Generation Inference.\n",
    "\n",
    "\n",
    "_Note: Make sure you build the container with the `patch` for the Golden Gate models._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations\n",
    "\n",
    "Before we can install the packages make sure you have the cli installed: https://cloud.google.com/sdk/docs/install\n",
    "\n",
    "Install the packages required for executing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade --quiet google-cloud-aiplatform google-cloud-storage \"google-auth>=2.23.3\"\n",
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab only: Uncomment the following cell to restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Vertex AI and SDK\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below.\n",
    "\n",
    "**1. Vertex AI Workbench**\n",
    "* Do nothing as you are already authenticated.\n",
    "\n",
    "**2. Local JupyterLab instance, uncomment and run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to the following link in your browser:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=6fajmwQMFZ0ouvoHuQXEsle3oxNHu1&prompt=consent&access_type=offline&code_challenge=QkTl4yDx9R0W-2EY2-VqcdVQayB9gIB1yzEnja_rEwI&code_challenge_method=S256\n",
      "\n",
      "Enter authorization code: ^C\n",
      "\n",
      "\n",
      "Command killed by keyboard interrupt\n",
      "\n",
      "Go to the following link in your browser:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=YmqcmaWYR4o2gfG6xtb3ac3WSXojzA&prompt=consent&access_type=offline&code_challenge=8QHsJC8MuNKeQAKeCCbpaIZboomCWnsvhIkLGJGVbIs&code_challenge_method=S256\n",
      "\n",
      "Enter authorization code: "
     ]
    }
   ],
   "source": [
    "! gcloud auth login \n",
    "! gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Colab, uncomment and run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Service account or other**\n",
    "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup SDK with your project id\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [ai/region].\n",
      "Creating gs://vertexai-huggingface-ml-tgi/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'vertexai-huggingface-ml-tgi' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
     ]
    }
   ],
   "source": [
    "# PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "PROJECT_ID = \"huggingface-ml\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
    "BUCKET_URI = f\"gs://vertexai-{PROJECT_ID}-tgi\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID} --quiet\n",
    "# Set the region\n",
    "! gcloud config set ai/region {REGION} --quiet\n",
    "# create the bucket if it doesn't exist\n",
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following set of constants will be used to create names and display names of Vertex AI Prediction resources like models, endpoints, and model deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model names and version\n",
    "MODEL_NAME = \"Golden-Gate-7b\" # @param {type:\"string\"}\n",
    "MODEL_VERSION = \"v01\" # @param {type: \"string\"}\n",
    "MODEL_DISPLAY_NAME = f\"TGI-{MODEL_NAME}-{MODEL_VERSION}\" # @param {type:\"string\"}\n",
    "ENDPOINT_DISPLAY_NAME = f\"endpoint-{MODEL_NAME}-{MODEL_VERSION}\" # @param {type:\"string\"}\n",
    "\n",
    "# You can get the latest Triton image uri from\n",
    "# https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference\n",
    "DOCKER_ARTIFACT_REPO = \"custom-tgi-example\" # @param {type:\"string\"}\n",
    "BASE_TGI_IMAGE = \"ghcr.io/huggingface/text-generation-inference:latest\" # @param {type:\"string\"}\n",
    "SERVING_CONTAINER_IMAGE_URI = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{DOCKER_ARTIFACT_REPO}/base-tgi-image:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Push TGI image to Container Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current image is created with the patch \n",
    "\n",
    "# push-to-gcr.sh script\n",
    "\n",
    "# ! gcloud services enable artifactregistry.googleapis.com\n",
    "\n",
    "# # create a new Docker repository with your region with the description\n",
    "# ! gcloud artifacts repositories create {DOCKER_ARTIFACT_REPO} \\\n",
    "#     --repository-format=docker \\\n",
    "#     --location={REGION} \\\n",
    "#     --description=\"Custom TGI Example\"\n",
    "\n",
    "# # verify that your repository was created.\n",
    "# ! gcloud artifacts repositories list \\\n",
    "#     --location={REGION} \\\n",
    "#     --filter=\"name~\"{DOCKER_ARTIFACT_REPO}\n",
    "\n",
    "# # configure docker to use your repository    \n",
    "# ! gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet\n",
    "    \n",
    "# # pull, tag and push\n",
    "# ! docker pull {BASE_TGI_IMAGE}\n",
    "# ! docker tag {BASE_TGI_IMAGE} {SERVING_CONTAINER_IMAGE_URI}\n",
    "# ! docker push {SERVING_CONTAINER_IMAGE_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy model to Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/1049843053967/locations/us-central1/models/1731948517049499648/operations/4396258636477759488\n",
      "Model created. Resource name: projects/1049843053967/locations/us-central1/models/1731948517049499648@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/1049843053967/locations/us-central1/models/1731948517049499648@1')\n",
      "TGI-mistral-7b-hf-v01\n",
      "projects/1049843053967/locations/us-central1/models/1731948517049499648\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    # artifact_uri=f\"{BUCKET_URI}/{MODEL_NAME}\",\n",
    "    serving_container_image_uri=SERVING_CONTAINER_IMAGE_URI,\n",
    "    serving_container_predict_route=\"/v1/endpoint\",\n",
    "    serving_container_health_route=\"/health\",\n",
    "    serving_container_environment_variables={\n",
    "        \"MODEL_ID\": \"gg-hf/golden-gate-7b\",\n",
    "        \"NUM_SHARD\": \"1\",\n",
    "        \"MAX_INPUT_LENGTH\": \"1512\",\n",
    "        \"MAX_TOTAL_TOKENS\": \"4096\",\n",
    "        #\"HUGGING_FACE_HUB_TOKEN\": \"TOKEN WITH ACCESS TO THE PRIVATE REPO\",\n",
    "        \"HUGGING_FACE_HUB_TOKEN\": \"\",\n",
    "        },\n",
    "    serving_container_ports=[80],\n",
    ")\n",
    "\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/1049843053967/locations/us-central1/endpoints/8815701712577757184/operations/6215712885935439872\n",
      "Endpoint created. Resource name: projects/1049843053967/locations/us-central1/endpoints/8815701712577757184\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/1049843053967/locations/us-central1/endpoints/8815701712577757184')\n",
      "Deploying model to Endpoint : projects/1049843053967/locations/us-central1/endpoints/8815701712577757184\n",
      "Deploy Endpoint model backing LRO: projects/1049843053967/locations/us-central1/endpoints/8815701712577757184/operations/216918182277939200\n",
      "Endpoint model deployed. Resource name: projects/1049843053967/locations/us-central1/endpoints/8815701712577757184\n"
     ]
    }
   ],
   "source": [
    "machine_type = 'g2-standard-4' # L4 GPUs\n",
    "endpoint = aiplatform.Endpoint.create(display_name=ENDPOINT_DISPLAY_NAME)\n",
    "\n",
    "deployed_model = model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=MODEL_NAME,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_type=\"NVIDIA_L4\",\n",
    "    accelerator_count=1,\n",
    "    traffic_percentage=100,\n",
    "    min_replica_count=1,\n",
    "    sync=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Google Cloud is a suite of cloud computing services offered by Google. It provides a range of infrastructure and platform solutions for businesses and developers, including storage, computing power, networking, and various software services. Google Cloud allows users to build, deploy, and scale applications, websites, and services on the same infrastructure that Google uses internally for its own offerings. This infrastructure is designed to be reliable, scalable, and secure, and offers flexible pricing models to fit different budgets and usage patterns. Services in Google Cloud include Google Compute Engine for virtual machines, Google Storage for data storage, Google App Engine for application hosting, Google Kubernetes Engine for container orchestration, BigQuery for analytics, and many others. Google Cloud also integrates with other Google services like Google Drive, Google Docs, and Google Maps for additional functionality. The goal of Google Cloud is to help businesses and developers build, deploy, and run applications and services with ease and flexibility, while leveraging Google's expertise in areas like machine learning, data analytics, and security.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "prompt = \"Deep Learning is\"\n",
    "\n",
    "res = deployed_model.predict(instances=[\n",
    "  {\"inputs\": prompt, \n",
    "   \"parameters\": {\"max_new_tokens\": 256, \"do_sample\": True, \"top_p\": 0.7, \"temparature\": 1.0 }}\n",
    "  ]\n",
    ")\n",
    "print(res.predictions[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying Endpoint model: projects/1049843053967/locations/us-central1/endpoints/3364094363645771776\n",
      "Undeploy Endpoint model backing LRO: projects/1049843053967/locations/us-central1/endpoints/3364094363645771776/operations/2355565055325503488\n",
      "Endpoint model undeployed. Resource name: projects/1049843053967/locations/us-central1/endpoints/3364094363645771776\n",
      "Deleting Endpoint : projects/1049843053967/locations/us-central1/endpoints/3364094363645771776\n",
      "Delete Endpoint  backing LRO: projects/1049843053967/locations/us-central1/operations/4209922201895305216\n",
      "Endpoint deleted. . Resource name: projects/1049843053967/locations/us-central1/endpoints/3364094363645771776\n",
      "Deleting Model : projects/1049843053967/locations/us-central1/models/7037188878091943936\n",
      "Delete Model  backing LRO: projects/1049843053967/locations/us-central1/models/7037188878091943936/operations/2782281120018857984\n",
      "Model deleted. . Resource name: projects/1049843053967/locations/us-central1/models/7037188878091943936\n"
     ]
    }
   ],
   "source": [
    "deployed_model.undeploy_all()\n",
    "deployed_model.delete()\n",
    "model.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
