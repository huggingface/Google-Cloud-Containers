{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Golden Gate 7B on Vertex AI \n",
    "\n",
    "This tutorial demonstrates how to deploy Golden Gate to Vertex AI using Hugging Face Text Generation Inference.\n",
    "\n",
    "_Note: Make sure you build the container with the `patch` for the Golden Gate models._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations\n",
    "\n",
    "Before we can install the packages make sure you have the cli installed: https://cloud.google.com/sdk/docs/install\n",
    "\n",
    "Install the packages required for executing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade --quiet google-cloud-aiplatform google-cloud-storage \"google-auth>=2.23.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Vertex AI and SDK\n",
    "\n",
    "Login to gcloud and set your project id.\n",
    "\n",
    "```bash\n",
    "gcloud auth login \n",
    "gcloud auth application-default login\n",
    "``````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup SDK with your project id\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "PROJECT_ID = \"huggingface-ml\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
    "BUCKET_URI = f\"gs://vertexai-{PROJECT_ID}-tgi\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID} --quiet\n",
    "# Set the region\n",
    "! gcloud config set ai/region {REGION} --quiet\n",
    "# create the bucket if it doesn't exist\n",
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following set of constants will be used to create names and display names of Vertex AI Prediction resources like models, endpoints, and model deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model names and version\n",
    "MODEL_NAME = \"Golden-Gate-7b\" # @param {type:\"string\"}\n",
    "MODEL_VERSION = \"v01\" # @param {type: \"string\"}\n",
    "MODEL_DISPLAY_NAME = f\"TGI-{MODEL_NAME}-{MODEL_VERSION}\" # @param {type:\"string\"}\n",
    "ENDPOINT_DISPLAY_NAME = f\"endpoint-{MODEL_NAME}-{MODEL_VERSION}\" # @param {type:\"string\"}\n",
    "\n",
    "# https://github.com/huggingface/text-generation-inference/pkgs/container/text-generation-inference\n",
    "DOCKER_ARTIFACT_REPO = \"custom-tgi-example\" # @param {type:\"string\"}\n",
    "BASE_TGI_IMAGE = \"ghcr.io/huggingface/text-generation-inference:latest\" # @param {type:\"string\"}\n",
    "SERVING_CONTAINER_IMAGE_URI = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{DOCKER_ARTIFACT_REPO}/base-tgi-image:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deploy model to Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/1049843053967/locations/us-central1/models/4312862947253682176/operations/393893374861508608\n",
      "Model created. Resource name: projects/1049843053967/locations/us-central1/models/4312862947253682176@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/1049843053967/locations/us-central1/models/4312862947253682176@1')\n",
      "TGI-Golden-Gate-7b-v01\n",
      "projects/1049843053967/locations/us-central1/models/4312862947253682176\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    serving_container_image_uri=SERVING_CONTAINER_IMAGE_URI,\n",
    "    serving_container_environment_variables={\n",
    "        \"MODEL_ID\": \"gg-hf/golden-gate-7b\",\n",
    "        \"NUM_SHARD\": \"1\",\n",
    "        \"MAX_INPUT_LENGTH\": \"512\",\n",
    "        \"MAX_TOTAL_TOKENS\": \"1024\",\n",
    "        \"MAX_BATCH_PREFILL_TOKENS\": \"1512\",\n",
    "        \"HUGGING_FACE_HUB_TOKEN\": \"TOKEN WITH ACCESS TO THE PRIVATE REPO\",\n",
    "        },\n",
    "    serving_container_ports=[80],\n",
    ")\n",
    "\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deployment will take ~20-25 minutes. You can check the status of the deployment in the cloud console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/1049843053967/locations/us-central1/endpoints/60211455760269312/operations/1744973263072657408\n",
      "Endpoint created. Resource name: projects/1049843053967/locations/us-central1/endpoints/60211455760269312\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/1049843053967/locations/us-central1/endpoints/60211455760269312')\n",
      "Deploying model to Endpoint : projects/1049843053967/locations/us-central1/endpoints/60211455760269312\n",
      "Deploy Endpoint model backing LRO: projects/1049843053967/locations/us-central1/endpoints/60211455760269312/operations/7087368321040908288\n",
      "Endpoint model deployed. Resource name: projects/1049843053967/locations/us-central1/endpoints/60211455760269312\n"
     ]
    }
   ],
   "source": [
    "machine_type = 'g2-standard-4' # L4 GPUs\n",
    "endpoint = aiplatform.Endpoint.create(display_name=ENDPOINT_DISPLAY_NAME)\n",
    "\n",
    "deployed_model = model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=MODEL_NAME,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_type=\"NVIDIA_L4\",\n",
    "    accelerator_count=1,\n",
    "    traffic_percentage=100,\n",
    "    min_replica_count=1,\n",
    "    sync=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning is the upcoming technology trend that is widening its stakes in the mobile app industry and which might transform the way things are done. With significant advancements in the deep learning techniques, mobile apps have also started using deep learning techniques in order to make themselves better and more efficient than ever. The use of deep learning is a hot topic now and after witnessing the way people are passionate enough to make deep learning techniques for the smartphones, these techniques have become the most anticipated technological breakthrough today.\n",
      "\n",
      "The novel research have marked the excellence of deep learning in the field of mobile analytics where the insights provided by the trained networks has boosted the productivity of the apps and also helped the app developers in providing a better insight about the app usage .  It helps the app developers and marketers to understand the various application enhancements, issues, and users needs better. Nowadays, deep learning algorithms are being used in answering real time complex questions based on the specific machine settings and running the application in an efficient manner.\n",
      "\n",
      "Deep learning algorithms help the developers to understand the distance from the cameras camera, the ambient temperature during the biometric authentication, reduce the error rate in text messaging by locking down mobile messaging. The deep learning doesnâ€™t just predicts a simple, granular data for the clients, it also predicts the actionable advancement.  Let us\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Deep Learning is\"\n",
    "\n",
    "res = deployed_model.predict(instances=[\n",
    "  {\"inputs\": prompt, \n",
    "   \"parameters\": {\"max_new_tokens\": 256, \"do_sample\": True, \"top_p\": 0.95, \"temparature\": 1.0 }}\n",
    "  ]\n",
    ")\n",
    "print(prompt + res.predictions[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying Endpoint model: projects/1049843053967/locations/us-central1/endpoints/60211455760269312\n",
      "Undeploy Endpoint model backing LRO: projects/1049843053967/locations/us-central1/endpoints/60211455760269312/operations/3646618205729849344\n",
      "Endpoint model undeployed. Resource name: projects/1049843053967/locations/us-central1/endpoints/60211455760269312\n",
      "Deleting Endpoint : projects/1049843053967/locations/us-central1/endpoints/60211455760269312\n",
      "Delete Endpoint  backing LRO: projects/1049843053967/locations/us-central1/operations/5055118989189971968\n",
      "Endpoint deleted. . Resource name: projects/1049843053967/locations/us-central1/endpoints/60211455760269312\n",
      "Deleting Model : projects/1049843053967/locations/us-central1/models/4312862947253682176\n",
      "Delete Model  backing LRO: projects/1049843053967/locations/us-central1/models/4312862947253682176/operations/8450833108227325952\n",
      "Model deleted. . Resource name: projects/1049843053967/locations/us-central1/models/4312862947253682176\n"
     ]
    }
   ],
   "source": [
    "deployed_model.undeploy_all()\n",
    "deployed_model.delete()\n",
    "model.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
