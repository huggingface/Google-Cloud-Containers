# Available DLCs on Google Cloud

Below you can find a listing of all the Deep Learning Containers (DLCs) available on Google Cloud. Containers are created for each supported combination of use-case (training, inference), accelerator type (CPU, GPU, TPU), and framework (PyTorch, TGI, TEI).

<Tip>

The listing below only contains the latest version of each one of the Hugging Face DLCs, the full listing of the available published containers in Google Cloud can be found either in the [Google Cloud Deep Learning Containers Documentation](https://cloud.google.com/deep-learning-containers/docs/choosing-container#hugging-face), in the [Google Cloud Artifact Registry](https://console.cloud.google.com/artifacts/docker/deeplearning-platform-release/us/gcr.io) or via the `gcloud container images list --repository="us-docker.pkg.dev/deeplearning-platform-release/gcr.io" | grep "huggingface-"` command.

</Tip>

## Text Generation Inference (TGI)

Text Generation Inference (TGI) DLC is available for high-performance text generation of Large Language Models on both GPU and TPU (soon). The TGI DLC enables you to deploy [any of the +140,000 text generation inference supported models from the Hugging Face Hub](https://huggingface.co/models?other=text-generation-inference&sort=trending), or any custom model as long as [its architecture is supported within TGI](https://huggingface.co/docs/text-generation-inference/supported_models).

| Container URI                                                                                                                     | Path                                                                                                                                               | Accelerator |
| --------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- | ----------- |
| us-docker.pkg.dev/deeplearning-platform-release/gcr.io/huggingface-text-generation-inference-cu124.2-3.ubuntu2204.py311           | [text-generation-inference-gpu.2.3.1](https://github.com/huggingface/Google-Cloud-Containers/tree/main/containers/tgi/gpu/2.3.1/Dockerfile)                                                                       | GPU         |

## Text Embeddings Inference (TEI)

Text Embeddings Inference (TEI) DLC is available for high-performance serving of embedding models on both GPU and GPU. The TEI DLC enables you to deploy [any of the +10,000 embedding, re-ranking or sequence classification supported models from the Hugging Face Hub](https://huggingface.co/models?other=text-embeddings-inference&sort=trending), or any custom model as long as [its architecture is supported within TEI](https://huggingface.co/docs/text-embeddings-inference/en/supported_models).

| Container URI                                                                                                                     | Path                                                                                                                                               | Accelerator |
| --------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- | ----------- |
| us-docker.pkg.dev/deeplearning-platform-release/gcr.io/huggingface-text-embeddings-inference-cu122.1-4.ubuntu2204                 | [text-embeddings-inference-gpu.1.4.0](https://github.com/huggingface/Google-Cloud-Containers/tree/main/containers/tei/gpu/1.4.0/Dockerfile)                                                                       | GPU         |
| us-docker.pkg.dev/deeplearning-platform-release/gcr.io/huggingface-text-embeddings-inference-cpu.1-4                              | [text-embeddings-inference-cpu.1.4.0](https://github.com/huggingface/Google-Cloud-Containers/tree/main/containers/tei/cpu/1.4.0/Dockerfile)                                                                       | CPU         |

## PyTorch Inference

Pytorch Inference DLC is available for Pytorch via ðŸ¤— Transformers, for serving models trained with ðŸ¤— TRL, Sentence Transformers or ðŸ§¨ Diffusers, on both CPU and GPU.

| Container URI                                                                                                                     | Path                                                                                                                                               | Accelerator |
| --------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- | ----------- |
| us-docker.pkg.dev/deeplearning-platform-release/gcr.io/huggingface-pytorch-inference-cu121.2-2.transformers.4-44.ubuntu2204.py311 | [huggingface-pytorch-inference-gpu.2.2.2.transformers.4.44.0.py311](https://github.com/huggingface/Google-Cloud-Containers/tree/main/containers/pytorch/inference/gpu/2.2.2/transformers/4.44.0/py311/Dockerfile) | GPU         |
| us-docker.pkg.dev/deeplearning-platform-release/gcr.io/huggingface-pytorch-inference-cpu.2-2.transformers.4-44.ubuntu2204.py311   | [huggingface-pytorch-inference-cpu.2.2.2.transformers.4.44.0.py311](https://github.com/huggingface/Google-Cloud-Containers/tree/main/containers/pytorch/inference/cpu/2.2.2/transformers/4.44.0/py311/Dockerfile) | CPU         |

## PyTorch Training

Pytorch Training DLC is available for PyTorch via ðŸ¤— Transformers. It includes support for training with libraries such as ðŸ¤— TRL, Sentence Transformers, or ðŸ§¨ Diffusers, on both GPUs and TPUs (soon).

| Container URI                                                                                                                     | Path                                                                                                                                               | Accelerator |
| --------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- | ----------- |
| us-docker.pkg.dev/deeplearning-platform-release/gcr.io/huggingface-pytorch-training-cu121.2-3.transformers.4-42.ubuntu2204.py310  | [huggingface-pytorch-training-gpu.2.3.0.transformers.4.42.3.py310](https://github.com/huggingface/Google-Cloud-Containers/tree/main/containers/pytorch/training/gpu/2.3.0/transformers/4.42.3/py310/Dockerfile)   | GPU         |
